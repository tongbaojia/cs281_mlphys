{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import argv\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir):\n",
    "    fs = [data_dir + f for f in os.listdir(data_dir) if ('signal' in f or 'WZ' in f) and f[0] != '.']\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for f in fs:\n",
    "        print f\n",
    "        new_df = pd.read_csv(f)\n",
    "        df = pd.concat([df, new_df], ignore_index = True)\n",
    "        df.index = range(len(df))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cl_ix(df):\n",
    "    df['is_sig'] = [1 if 'signal' in val else 0 for val in df.cl.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WWdataset(Dataset):\n",
    "\n",
    "    def __init__(self, pd_dataset):\n",
    "        self.dataset = pd_dataset\n",
    "\n",
    "        self.input_vars = [col for col in self.dataset.columns if not col in ['runNumber', 'lbNumber', 'eventNumber', 'SFOS', 'is_sig', 'weight', 'cl', 'preds']]\n",
    "\n",
    "        self.target_var = ['is_sig']\n",
    "        self.weight_var = ['weight']\n",
    "\n",
    "        self.input_np = self.dataset[self.input_vars].as_matrix().astype(dtype=np.float32)\n",
    "        self.target_np = self.dataset[self.target_var].as_matrix().astype(dtype=int)\n",
    "        self.weight_np =self.dataset[self.weight_var].as_matrix().astype(dtype=np.float32)\n",
    "\n",
    "        self.inputs = torch.from_numpy(self.input_np)\n",
    "        self.target = torch.from_numpy(self.target_np)\n",
    "        self.weight = torch.from_numpy(self.weight_np)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.inputs[idx]\n",
    "        target = self.target[idx]\n",
    "        weight = self.weight[idx]\n",
    "        return inputs, target, weight\n",
    "\n",
    "    def n_input(self):\n",
    "        return len(self.input_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_logistic_regression(n_input):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n_input, 2),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_deep_logistic_regression(n_input):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(n_input, 100),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(100, 10),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(10, 2),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/bkg_WZqqll.csv\n",
      "../data/signal_WmWpWm.csv\n",
      "../data/bkg_WZlvll.csv\n",
      "../data/signal_WpWpWm.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "pandas_dataset = add_cl_ix(get_data(data_dir))\n",
    "\n",
    "in_dataset = WWdataset(pandas_dataset)\n",
    "trainloader = torch.utils.data.DataLoader(in_dataset, batch_size=200, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = net_logistic_regression(in_dataset.n_input())\n",
    "net = net_deep_logistic_regression(in_dataset.n_input())\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:  0\n",
      "batch:  200, loss: 0.125596643128\n",
      "batch:  400, loss: 0.113505237438\n",
      "batch:  600, loss: 0.107505051469\n",
      "batch:  800, loss: 0.102837853758\n",
      "batch:  1000, loss: 0.0991723927259\n",
      "batch:  1200, loss: 0.0966603812389\n",
      "batch:  1400, loss: 0.094770425284\n",
      "batch:  1600, loss: 0.0931869727024\n",
      "batch:  1800, loss: 0.0919440372268\n",
      "batch:  2000, loss: 0.09094005966\n",
      "batch:  2200, loss: 0.0900775078989\n",
      "batch:  2400, loss: 0.0895538578555\n",
      "batch:  2600, loss: 0.0889533599208\n",
      "batch:  2800, loss: 0.0884405116298\n",
      "batch:  3000, loss: 0.0880515721105\n",
      "batch:  3200, loss: 0.0876767563447\n",
      "batch:  3400, loss: 0.087328800845\n",
      "\n",
      "epoch:  1\n",
      "batch:  200, loss: 0.0816475995071\n",
      "batch:  400, loss: 0.0817221077718\n",
      "batch:  600, loss: 0.0814491656981\n",
      "batch:  800, loss: 0.081532221497\n",
      "batch:  1000, loss: 0.0815525682978\n",
      "batch:  1200, loss: 0.0816104552553\n",
      "batch:  1400, loss: 0.0816084949992\n",
      "batch:  1600, loss: 0.0814760368527\n",
      "batch:  1800, loss: 0.0814452114598\n",
      "batch:  2000, loss: 0.0814621690642\n",
      "batch:  2200, loss: 0.0814928649806\n",
      "batch:  2400, loss: 0.0813776136981\n",
      "batch:  2600, loss: 0.0812905899994\n",
      "batch:  2800, loss: 0.0812919897214\n",
      "batch:  3000, loss: 0.0812366917282\n",
      "batch:  3200, loss: 0.0811843448842\n",
      "batch:  3400, loss: 0.081201820333\n",
      "\n",
      "epoch:  2\n",
      "batch:  200, loss: 0.0803354735114\n",
      "batch:  400, loss: 0.0812381205428\n",
      "batch:  600, loss: 0.0808304236581\n",
      "batch:  800, loss: 0.0805928972457\n",
      "batch:  1000, loss: 0.0806125077605\n",
      "batch:  1200, loss: 0.0804658191434\n",
      "batch:  1400, loss: 0.0803607629373\n",
      "batch:  1600, loss: 0.0805528983613\n",
      "batch:  1800, loss: 0.0805113449962\n",
      "batch:  2000, loss: 0.0805223486945\n",
      "batch:  2200, loss: 0.0804513389448\n",
      "batch:  2400, loss: 0.0803716615479\n",
      "batch:  2600, loss: 0.0803587621035\n",
      "batch:  2800, loss: 0.0802545922436\n",
      "batch:  3000, loss: 0.080200881506\n",
      "batch:  3200, loss: 0.0801632574911\n",
      "batch:  3400, loss: 0.0801823498769\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "        print\n",
    "        print \"epoch: \", epoch\n",
    "        running_loss = 0.\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, label, weight = data\n",
    "            inputs, label, weight = Variable(inputs), Variable(label), Variable(weight)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = net(inputs)\n",
    "            losses = criterion(output, label.squeeze())\n",
    "            loss = (losses * weight.squeeze()).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 200 == 199:    # print every 2000 mini-batches\n",
    "                print \"batch:  {}, loss: {}\".format(i+1, running_loss/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         10.827804\n",
       "1          8.728285\n",
       "2         10.333354\n",
       "3          6.235691\n",
       "4          7.109641\n",
       "5          0.000000\n",
       "6         39.645454\n",
       "7          3.069092\n",
       "8          3.836800\n",
       "9          1.443163\n",
       "10         8.151371\n",
       "11         0.000000\n",
       "12         7.227347\n",
       "13         7.291297\n",
       "14         7.812573\n",
       "15         3.978964\n",
       "16        16.059092\n",
       "17        11.954015\n",
       "18        10.873179\n",
       "19        11.764853\n",
       "20         5.794008\n",
       "21         1.782322\n",
       "22         6.860672\n",
       "23        20.722750\n",
       "24         2.241212\n",
       "25         8.853338\n",
       "26         8.894777\n",
       "27        11.313497\n",
       "28         0.000000\n",
       "29         9.279571\n",
       "            ...    \n",
       "693981    15.664246\n",
       "693982     0.000000\n",
       "693983     3.116730\n",
       "693984    14.984694\n",
       "693985    11.677755\n",
       "693986     4.970895\n",
       "693987     0.000000\n",
       "693988     5.095598\n",
       "693989     0.000000\n",
       "693990     0.000000\n",
       "693991     8.907316\n",
       "693992     4.212761\n",
       "693993     9.801770\n",
       "693994     0.000000\n",
       "693995     6.341951\n",
       "693996     0.000000\n",
       "693997     0.000000\n",
       "693998    13.683038\n",
       "693999     0.000000\n",
       "694000     0.000000\n",
       "694001     0.000000\n",
       "694002     6.363422\n",
       "694003    28.058771\n",
       "694004     0.000000\n",
       "694005     5.787813\n",
       "694006    10.825871\n",
       "694007     0.000000\n",
       "694008     5.671014\n",
       "694009     0.000000\n",
       "694010     0.000000\n",
       "Name: j0_m, Length: 694011, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9.9836e-01  1.6404e-03\n",
       " 9.9847e-01  1.5276e-03\n",
       " 9.9871e-01  1.2862e-03\n",
       "           ⋮            \n",
       " 9.9165e-01  8.3478e-03\n",
       " 9.9066e-01  9.3382e-03\n",
       " 9.8159e-01  1.8407e-02\n",
       "[torch.FloatTensor of size 694011x2]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(net(Variable(in_dataset.inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_pred = Variable(in_dataset.inputs)\n",
    "predicted_scores = net(input_for_pred)\n",
    "predicted_prob = nn.functional.softmax(predicted_scores, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
